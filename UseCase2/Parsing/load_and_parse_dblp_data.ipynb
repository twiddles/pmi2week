{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parsing with lxml lib using parse() utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import pandas as pd\n",
    "\n",
    "#validate xml egainst extrenal dtd file\n",
    "parser = etree.XMLParser(load_dtd=True) #load_dtd=True #dtd_validation=True\n",
    "tree = etree.parse(\"data/dblp.xml\", parser)\n",
    "root = tree.getroot()\n",
    "#note that parse() returns an ElementTree object, not an Element object as the string parser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize(text):\n",
    "    '''\n",
    "    Removes specific HTML Formatting Elements for italic text, i.e. <i>\n",
    "    # example <title><i> NP </i> -Hard Problems in Hierarchical-Tree Clustering.</title>\n",
    "    '''\n",
    "    if text:\n",
    "        return re.sub('<(/)*i>', u'', text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "string = '<i>text here</i>'\n",
    "re.sub('<(/)*i>', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "print(\"Parsing articles only...\")\n",
    "t0 = time()\n",
    "\n",
    "### parse the entire file\n",
    "dfcols = ['author', 'title', 'journal']\n",
    "df_xml = pd.DataFrame(columns=dfcols)\n",
    "\n",
    "collaborations = ['article']\n",
    "\n",
    "author_list = []\n",
    "\n",
    "#if 'key1' in dict.keys():\n",
    "\n",
    "for node in root:\n",
    "    if node.tag in collaborations:\n",
    "        for child in node:\n",
    "            if 'author' in child.tag:\n",
    "                author_list.append(child.text)\n",
    "                #print(child.text)\n",
    "            elif 'title' in child.tag:\n",
    "                title = sanitize(child.text)\n",
    "                #print(child.text) \n",
    "            elif 'journal' in child.tag:\n",
    "                journal = child.text\n",
    "                #print(child.text) \n",
    "        for a in author_list:\n",
    "            df_xml = df_xml.append(pd.Series([a, title, journal], index=dfcols), ignore_index = True)\n",
    "        #clearing a list \n",
    "        del author_list[:]\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "df_xml.to_csv(\"data/parsed_articles.csv\", header=True, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I let it run for an hour and it was not finished! We try another method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_xml.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parsing with lxml lib using parse interparse() utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize(text):\n",
    "    '''\n",
    "    Removes specific HTML Formatting Elements for italic text, i.e. <i>\n",
    "    # example <title><i> NP </i> -Hard Problems in Hierarchical-Tree Clustering.</title>\n",
    "    '''\n",
    "    return re.sub('<(/)*i>', u'', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parsing only one child element called article  \n",
    "\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "def fast_iter(context, func, *args, **kwargs):\n",
    "    collaborations = ['article']\n",
    "    author_list = []\n",
    "\n",
    "    for event, elem in context:\n",
    "     \n",
    "        if 'author' in elem.tag:\n",
    "            author_list.append(elem.text)\n",
    "            #print(elem.text)\n",
    "        elif 'title' in elem.tag:\n",
    "            if elem.text:\n",
    "                title = sanitize(elem.text) \n",
    "                #print(elem.text)\n",
    "        elif 'journal' in elem.tag:\n",
    "            journal = sanitize(elem.text)\n",
    "            #print(elem.text)   \n",
    "        \n",
    "        elif elem.tag in collaborations:\n",
    "            if len(author_list) is not 0:\n",
    "                for a in author_list:\n",
    "                    func(a + \",\" + title + \",\" + journal, *args, **kwargs)\n",
    "                title = ''\n",
    "                del author_list[:]    \n",
    "        \n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    del context            \n",
    "\n",
    "    \n",
    "def process_element(elem, fout):\n",
    "    #print(\"writing ... \" + elem)\n",
    "    print(elem, file = fout)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Parsing articles only...\")\n",
    "    t0 = time()\n",
    "    fout = open('data/parsed_articles.txt', 'w')\n",
    "    context = etree.iterparse('data/dblp.xml', load_dtd=True)\n",
    "    fast_iter(context, process_element, fout)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing all child elements, including www child element which is a person record\n",
    "\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "def fast_iter(context, func, *args, **kwargs):\n",
    "    collaborations = [u'www', u'article', u'phdthesis', u'inproceedings', u'incollection', u'proceedings', u'book', u'mastersthesis']\n",
    "    #collaborations = [u'article']\n",
    "    \n",
    "    author_list = []\n",
    "    title = ''\n",
    "    journal = ''\n",
    "\n",
    "    for event, elem in context:\n",
    "     \n",
    "        if 'author' in elem.tag:\n",
    "            author_list.append(elem.text)\n",
    "        \n",
    "        # use comparison instead of in. otherwise problems with proceedings and inproceedings child element\n",
    "        elif elem.tag == 'title':\n",
    "            #sometimes the elem.text returns None while there is a text inside\n",
    "            #<title><i> LALR </i> (1, 1) Parser Generation for Regular Right Part Grammars.</title>\n",
    "            if elem.text:\n",
    "                title = sanitize(elem.text) \n",
    "               \n",
    "        elif 'journal' in elem.tag:\n",
    "            if elem.text:\n",
    "                journal = sanitize(elem.text)\n",
    "             \n",
    "        elif elem.tag in collaborations:\n",
    "            type_publication = elem.tag \n",
    "            key_value = elem.get('key')\n",
    "            if len(author_list) is not 0:\n",
    "                for a in author_list:\n",
    "                    func(type_publication + \",\" + key_value + \",\" + a + \",\" + title + \",\" + journal, *args, **kwargs)\n",
    "                title = ''\n",
    "                journal = ''\n",
    "                type_publication = ''\n",
    "                key_value = ''\n",
    "                del author_list[:]    \n",
    "        \n",
    "        elem.clear()\n",
    "        #while elem.getprevious() is not None:\n",
    "        #    del elem.getparent()[0]\n",
    "    del context            \n",
    "\n",
    "    \n",
    "def process_element(elem, fout):\n",
    "    #print(\"writing ... \" + elem)\n",
    "    print(elem, file = fout)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Parsing...\")\n",
    "    t0 = time()\n",
    "    fout = open('/Users/aj186039/projects/PMI_UseCase/data/parsed_dblp.txt', 'w')\n",
    "    context = etree.iterparse('/Users/aj186039/projects/PMI_UseCase/data/dblp.xml', load_dtd = True)\n",
    "    fast_iter(context, process_element, fout)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"incollection\"\n",
    "\"collection\" in string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example person record\n",
    "\n",
    "<www key=\"homepages/r/CJvanRijsbergen\">\n",
    "<author>C. J. van Rijsbergen</author>\n",
    "<author>Cornelis Joost van Rijsbergen</author>\n",
    "<author>Keith van Rijsbergen</author>\n",
    "<title>Home Page</title>\n",
    "<url>http://www.dcs.gla.ac.uk/~keith/</url>\n",
    "</www>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import parsed data and map author names to its unique key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/Users/aj186039/projects/PMI_UseCase/data/parsed_dblp.txt', sep = ',', header=None, encoding='utf-8', \n",
    "                   names = [\"type_publication\", \"key_value\" , \"author\", \"title\", \"journal\"], low_memory=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the columns names of df\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values in a given df column\n",
    "data.type_publication.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select rows whose column value equals some value\n",
    "personal_data = data.loc[data['type_publication'] == 'www']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop rows whose column value equals some value\n",
    "data = data[data['type_publication'] != 'www']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return tuple representing the dimensionality of df\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "personal_data.drop(['type_publication','journal','title'] , axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the first 5 columns\n",
    "personal_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find specific person in data\n",
    "personal_data[personal_data['key_value'] == \"homepages/r/CJvanRijsbergen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group authors by its key value\n",
    "# for example all these names of authors should be grouped as they have unique key\n",
    "# {C. J. van Rijsbergen, Cornelis Joost van Rijsbergen, Keith van Rijsbergen} --> homepages/r/CJvanRijsbergen\n",
    "grouped_personal_data = personal_data.groupby('key_value')['author'].apply(list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the type of data object\n",
    "type(grouped_personal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictonary from the series\n",
    "dictinary_names = grouped_personal_data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up specific person\n",
    "dictinary_names[\"homepages/r/CJvanRijsbergen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the first 5 columns\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace in our data author names with corresponding keysm which are to be found in the above dict.\n",
    "# for example all these names authors used in his publications should be replace with one and the same key\n",
    "# {C. J. van Rijsbergen, Cornelis Joost van Rijsbergen, Keith van Rijsbergen} --> homepages/r/CJvanRijsbergen\n",
    "\n",
    "data['authorNEW'] = ''\n",
    "for idx,row  in data.iterrows():\n",
    "    result = [k for k, v in dictinary_names.items() if name_to_look in v]\n",
    "    if not result:\n",
    "        data.loc[idx, 'authorNEW'] = data.loc[idx, 'author']\n",
    "    else:\n",
    "        data.loc[idx, 'authorNEW'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I let it run for some time, the perfomance not satisfactory! Optimisation of the method required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the required behavior \n",
    "mydict = {'amber': ['Katerina', 'Almerima'] , 'george': ['Buba'], 'george2': ['Buba2']}\n",
    "name_to_look = 'Buba2'\n",
    "[k for k, v in mydict.items() if name_to_look in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data to text file\n",
    "data = pd.to_csv('/Users/aj186039/projects/PMI_UseCase/data/final_parsed_dblp.txt', sep = ',', header=True, encoding='utf-8')\n",
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
